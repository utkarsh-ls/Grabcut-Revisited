# GrabCut Algorithm

### About GrabCut
GrabCut is an interactive foreground extraction algorithm with minimal user interaction. It is used to accurately segment the foreground of an image from the background.

### Algorithm
1.  GrabCut works by attributing a label to each pixel in the image (or image segmentation). Each pixel is assigned an alpha value based on whether it is in the foreground region (referred to as $T_F$ where $\alpha = 1$) or the background region (referred to as $T_B$ where $\alpha = 0$) of the image. The rest of the pixels are unknown (referred to as $T_U$), having $0 \leq \alpha \leq 1$, and the algorithm iteratively this $\alpha$ value.
2.  The user starts by manually drawing a rectangular box around the region of interest in the image. Once the region is selected, everything outside the box is hard segmented as the background region ($T_B$ assigned $\alpha=0$), while everything in the box is unknown ($T_U$).
3. A gaussian mixture model (GMM) is applied over the image and this model understands the user input and starts creating labels for unknown pixel values. The unknown pixels are labelled either probable foreground or probable background depending on thier relation with the other hard-labelled pixels in terms of color statistics.
4. Based on the above pixel distribution, a graph is generated where these pixels are considered as nodes. Apart from this, we also have two other nodes called Source node (which will be connected to all the foreground pixels) and Sink node (which will be connected to all the background pixels). The edges connecting the pixels with the source node or the sink node contains the weights (which is basically the probability of whether the pixel is a foreground one or background one). These weights between the pixels are defined by the edge information or pixel similarity.
5. Now using the mincut algorithm, the image is segmented into two parts, separating the source node and the sink node with the help of a cost function which is the sum of all weights of the edges that are segmented.
6. Now, we have an image where the background and foreground are separated, although the separation is not completely accurate. The user can further imporove this segmentation by manually specifying parts of the image as either background, foreground, probable background, or probable foreground with the help of brush strokes. Here, the algorithm hard-labels all the user inputs specifying the foreground and background pixels.
